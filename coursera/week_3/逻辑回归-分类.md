## 1. 逻辑回归
逻辑回归（Logistic Regression）是一种用于解决二分类（0 or 1）问题的机器学习方法, 用于估计某种事物的`可能性`
比如邮件是否是垃圾邮件, 某用户购买某商品的可能性, 某病人患有某种疾病的可能性, 以及某广告被用户点击的可能性等

注意, 这里用的是“可能性”, 而非数学上的“概率”, 逻辑回归的结果并非数学定义中的概率值, 不可以直接当做概率值来用

逻辑回归（Logistic Regression）与线性回归（Linear Regression）都是一种广义线性模型（generalized linear model）
逻辑回归假设因变量 y 服从`伯努利分布`，而线性回归假设因变量 y 服从`高斯分布`

## 2. 逻辑回归模型
![](https://camo.githubusercontent.com/a8e65f2dafbb4e6c4e3a9c61c748e49a78f964ad/687474703a2f2f696d672e626c6f672e6373646e2e6e65742f3230313630343138313930373331333131)

线性回归模型中假设函数H(x), 预测的值是连续的, 并且值域区间在`[−∞,+∞]`

回到逻辑回归模型中, 我们希望假设函数H(x)最终的预测值是离散的0和1, 逻辑回归中假设函数如下

![](http://52opencourse.com/?qa=blob&qa_blobid=10421873245604717587)

![](http://img.blog.csdn.net/20160409203810378)

其中`theta`是参数, H(x)的直观解释为 `给定输入x, 参数化theta, y=1时的概率`
从数学上表示如下

![](http://img.blog.csdn.net/20160409203927593)

这个函数称为Sigmoid函数，也称为逻辑函数（Logistic function） 函数曲线如下

![](http://img.blog.csdn.net/20160409203837285)

从上图可以看到逻辑函数是一个s形的曲线，它的取值在[0,1]之间
当z = 0时, g(z) = 0.5; 当z > 0的时候函数值趋近于1; 当z < 0的时候函数值趋近于0



## 3. 决策边界
`决策边界，也称为决策面，是用于在N维空间，将不同类别样本分开的平面或曲面。决策边界实际上是一个方程，`

首先看一张图

![](http://52opencourse.com/?qa=blob&qa_blobid=17042785878272231122)

如图所示，我们希望找到一个`决策边界`











